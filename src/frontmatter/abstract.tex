\titlespacing*{\chapter}{0pt}{0pt}{0cm}
\newpage
\phantomsection
\addcontentsline{toc}{chapter}{ABSTRACT}
\chapter*{\titulos{ABSTRACT}}

Large Language Models (\textbf{LLMs}) have precipitated an asymmetric transformation in the contemporary cybersecurity ecosystem, where brute force attacks evolve autonomously to circumvent established detection mechanisms. This research evaluates the performance of conventional \textbf{IDS/IPS} systems against polymorphic attacks that dynamically modify their behavioral patterns and credential compromise strategies, exposing a critical disparity between adaptive offense and static defenses.

Systematic analysis of 147 publications revealed only 12 studies that satisfied strict inclusion criteria. Massive exclusions (n=123) resulted from absence of empirical validation, peripheral approaches to brute force, or lack of integration with LLM architectures. This limitation underscores a fundamental methodological gap: evaluation frameworks for traditional detection systems against AI-generated threats remain insufficiently developed.

Through \textbf{Design-Based Research} (DBR), we constructed an experimental environment that deployed 18 specialized prompts, generating 400 attacks distributed across 4 biweekly iterative cycles. Contextual roleplay techniques, instructional fragmentation, and progressive injection circumvented ethical restrictions of LLMs, producing scripts with unprecedented mutational capabilities absent in conventional signature repositories.

Autonomous agents deployed via conversational frameworks preserved persistent contextual stateâ€”a fundamental element for monitoring evolutionary patterns. This approach transcended conventional prompt engineering limitations, enabling autonomous decision-making and sustained operational scalability.

LLM-generated attacks achieved evasion rates exceeding 65% against standard IDS configurations. Specific vulnerabilities were identified: signature-based detection fails against regenerative code, variable temporal modulation, and directed polymorphism. In response, we developed 25 optimized rules that elevated detection effectiveness while maintaining false positive rates below 3%.

Proposed optimizations incorporate behavioral heuristics for mutational patterns, temporal correlation for distributed attacks, and evolutionary frameworks that counter continuous adaptation of LLM-generated threats. This research provides operational frameworks to modernize traditional detection systems against malicious exploitation of language models in automated attack generation.

\textbf{Keywords:} adaptive brute force attacks, malicious LLMs, IDS/IPS systems, polymorphic malware, evolutionary intrusion detection, cybersecurity evasion, offensive prompt engineering, Design-Based Research.

\titlespacing*{\chapter}{0pt}{50pt}{40pt} 
\glsresetall
\clearpage